from numpy import unique, nonzero, shape, mean, std, zeros,ones, arange, mod, asarray,c_,squeeze, round,argsort,sort
from scipy.stats.mstats import normaltest
from scipy.stats import f_oneway, shapiro, kstest,anderson,ks_2samp, ttest_ind
from scipy.stats.mstats import kruskalwallis
from pptx import Presentation
from pptx.util import Inches, Pt
from PIL import Image
from datetime import date
from os import listdir
from os.path import isfile, join
import matplotlib.pyplot as plt
from datetime import date
from DateTime import DateTime
from report_plugins import *
import glob

# generate the ppt with template
    
options.ppt_template = ('.\\Data\\workload.pptx')
if 'name' in locals(): 
    options.ppt_name = ((name+'.pptx'))
else:
    options.ppt_name = ('analysis_report.pptx')


prs = Presentation('.\\Data\workload.pptx')
slide_width=prs.slide_width/Inches(1);
slide_height=prs.slide_height/Inches(1);   


## create a title page
title_slide_layout = prs.slide_layouts[0]
slide = prs.slides.add_slide(title_slide_layout)

title = slide.shapes.title
title.text = 'Workload Analysis for Block Trace'
subtitle = slide.placeholders[13]
subtitle.text = "{:%m-%d-%Y}".format(date.today())

subtitle = slide.placeholders[10]
subtitle.text = "Generated by PBPA \nWDLABS"

## generate summary page 1

out_slide_layout = prs.slide_layouts[4]
# Create the summary graph
out_slide = prs.slides.add_slide(out_slide_layout)
title = out_slide.shapes.title
title.text = "Summary of Trace Properties"
subtitle = out_slide.placeholders[11]
subtitle.text = "Exective Summary"  
    
sub_lines=6   
font_size=item_font_size(sub_lines) 

subtitle = out_slide.placeholders[10]    
tf = subtitle.text_frame 
tf.text=''    

temp_str0='Read vs write '
if (basic_info.cmd_num_read > basic_info.cmd_num_write) and (basic_info.total_size_read > basic_info.total_size_write):
    temp_str11='Dominiated read requests'
else:
    if (basic_info.cmd_num_read < basic_info.cmd_num_write) and (basic_info.total_size_read < basic_info.total_size_write):
        temp_str11='Dominiated write requests'
    else:
        temp_str11='No dominated access'

temp_str12=(('R/W: cmd 1:'+str(basic_info.cmd_num_write / basic_info.cmd_num_read)+'; blks 1:'+str(basic_info.total_size_write / basic_info.total_size_read)))

temp_str2=[temp_str11,temp_str12]

add_items_to_tf(out_slide, temp_str0, temp_str2,font_size) 

# check sequence and randomness
options.seek = ([0.1,0.2,0.5,0.8])
options.seek_delta = [0.01,0.1,0.2]
temp_str1='Sequence vs Randomness'
temp_str21=check_sequence(seek_dist_record.seek_all,seek_dist_record.queue_len_setting,options)
temp_str21=(('Overall- '+temp_str21))
temp_str22=check_sequence(seek_dist_record.seek_write_only,seek_dist_record.queue_len_setting,options)
temp_str22=(('Write- '+temp_str22))
temp_str23=check_sequence(seek_dist_record.seek_read_only,seek_dist_record.queue_len_setting,options)
temp_str23=(('Read- '+temp_str23))
temp_str3=[temp_str21,temp_str22,temp_str23]
seq_rand_str=temp_str3

add_items_to_tf(out_slide, temp_str1, temp_str3,font_size)


## generate summary page 2

out_slide_layout = prs.slide_layouts[4]
# Create the summary graph
out_slide = prs.slides.add_slide(out_slide_layout)
title = out_slide.shapes.title
title.text = "Summary of Trace Properties (cont)"
subtitle = out_slide.placeholders[11]
subtitle.text = "Exective Summary"  
    
sub_lines=6   
font_size=item_font_size(sub_lines) 

subtitle = out_slide.placeholders[10]    
tf = subtitle.text_frame 
tf.text=''    

temp_str1='Write Update'
a1=size(time_wow_record.hit_ratio,1)
temp_str11='Update blk ratio: freq '+"{0:.3f}".format(1 -squeeze( freq_wow_record.freq_cdf[0]))+'& timed '+"{0:.3f}".format(squeeze(time_wow_record.update_ratio[a1-1]) / squeeze(time_wow_record.write_ratio[a1-1]))
temp_str12='Update cmd ratio: freq '+"{0:.3f}".format(1 - squeeze(freq_wow_record.c_freq_cdf[0]))+'& timed '+"{0:.3f}".format(squeeze(time_wow_record.hit_ratio[a1-1]) / squeeze(time_wow_record.write_cmd_ratio[a1-1]))
# check WORM /ROW
# check idle time
add_items_to_tf(out_slide, temp_str1, [temp_str11,temp_str12],font_size)

temp_str2='Idle time'
idx=nonzero(idle_queue_record.idle_time_array[:,1] > 0.1)
temp_str21=(('Total effective idle time (>0.1ms)='+"{0:.3f}".format(sum(idle_queue_record.idle_time_array[idx,1]))+'; Total idle time='+"{0:.3f}".format(sum(idle_queue_record.idle_time_array[:,1]))))
temp_str22=(('Total effective idle frequency (>0.1ms)='+str(shape(idx)[1])+'; Total idle frequency ='+str(len(idle_queue_record.idle_time_array))))

add_items_to_tf(out_slide, temp_str2, [temp_str21,temp_str22],font_size)

## generate basic information page

out_slide_layout = prs.slide_layouts[13]
out_slide = prs.slides.add_slide(out_slide_layout)
title = out_slide.shapes.title
title.text = "Basic Information"


subtitle = out_slide.placeholders[11]    
tf = subtitle.text_frame 
tf.text='' 

aa=len(lists_action)

temp_str1='Trace Information'
temp_str11=(('Maximum time = '+str(lists_action[aa-1,0])+'; effective time = '+str(lists_action[aa-1,0] - lists_action[0,0])))

add_items_to_tf(out_slide, temp_str1, [temp_str21],font_size,place_no=11)
temp_str2='Basic Statistics'
add_items_to_tf(out_slide, temp_str2, [''],font_size,place_no=11)

V=[[basic_info.cmd_num_read + basic_info.cmd_num_write,basic_info.cmd_num_read,basic_info.cmd_num_write],
    [basic_info.total_size_read + basic_info.total_size_write,basic_info.total_size_read,basic_info.total_size_write],
    [(basic_info.total_size_read + basic_info.total_size_write) / (basic_info.cmd_num_read + basic_info.cmd_num_write),basic_info.ave_size_read,basic_info.ave_size_write],
    [basic_info.iops_read + basic_info.iops_write,basic_info.iops_read,basic_info.iops_write],
    [basic_info.ave_tp_read + basic_info.ave_tp_write,basic_info.ave_tp_read,basic_info.ave_tp_write]]
    

shapes = out_slide.shapes
str_list=['','','Metrics']
y_list=['Combined','Read','Write']
x_list=['Cmd number','Total blk size','Average size (blk)','Average IOPS','Average TP (MBps)']
generate_table_page(prs, asarray(V), str_list,x_list,y_list,options=0,create_page=0,shapes=shapes, location=[0.6,3])


## generate LBA distribution

pic_name='lba_all.jpg'
im=Image.open(pic_name,'r')
iw,ih=im.size 
im.close()

height=4
width=(1.0*height/ih*iw)
top=1.3
left=((slide_width-width)/2)
str_list=["Request LBA Distribution",'Basic Properties' ]

locations=slide_info_class(width=width, height=height,top=top,left=left,font_size=14)
temp_str1='LBA vs Time can show the sequence and access range'
temp_str2='Visually observe if read and write are in the same/similar range'
temp_str3='Use a clustering method to find the access locality range'
content=[temp_str1,[],temp_str2,[],temp_str3,[]]
generate_1fig_page(prs,[pic_name],str_list, content, locations)
    
    
## generate iops/throughput slide

filenames0=glob.glob('./iops*.png')
filenames1=glob.glob('./throughput*.png')
filenames2=glob.glob('./reqsize*.png')
# Layout #11: 3Figure1Text (Title 1, Footer Placeholder 2, Picture_11, Picture_12, Picture_22, Text_main)
a1=len(filenames1)
width=4.5
height=3
width0=Inches(width)
height0=Inches(height)
top=1.3
left=1
tops=[top, top, top+height]
lefts=[left, left+width, left+width]

for i in arange(a1).reshape(-1):
    out_slide_layout = prs.slide_layouts[10]
    out_slide = prs.slides.add_slide(out_slide_layout)
    title = out_slide.shapes.title
    title.text = "Estimated IOPS and Throughput"
    subtitle = out_slide.placeholders[15]    
    tf = subtitle.text_frame 
    tf.text='Basic Properties' 
    for j in arange(3).reshape(-1):
        exec(('filenames=filenames'+str(j)))
        pic_name=filenames[i]
        pic = out_slide.shapes.add_picture(pic_name, Inches(lefts[j]), Inches(tops[j]), height=height0,width=width0) 
    temp_str1='Observe if burst and idleness exist'
    temp_str2='Bursts exist if there are peaks much higher than the average'
    temp_str3='Idleness exist if there are troughs much lower than the average'
    content=([temp_str1,temp_str2,temp_str3])
    add_items_to_tf2(out_slide, content,font_size,place_no=14)


## generate size distribution
filenames=(['size_dist_Combined.jpg','size_dist_write.jpg','size_dist_read.jpg'])
temp_str1='Observe the large-size requests for sequence and small-size requests for randomness'
temp_str2='The more large-size requests, the more sequetial in a sense '
content=([temp_str1,temp_str2])
str_list=["Size Distribution",'Basic Properties' ]
generate_3fig_page(prs,filenames,str_list, content)



## generate size distribution
req_size_dist=req_size_record.req_size_dist
req_size_cdf=req_size_record.req_size_cdf

a0=len(req_size_cdf)
for i in arange(3).reshape(-1):
    req_size_cdf[:,i]=req_size_cdf[:,i] / req_size_cdf[a0-1,i]


#   req_size_dist: request size distribution for " total, write, read"
idx_t=argsort(-req_size_dist[:,0])
idx_w=argsort(-req_size_dist[:,1])
idx_r=argsort(-req_size_dist[:,2])
va_t=req_size_dist[idx_t[0:5],0]
va_w=req_size_dist[idx_t[0:5],1]
va_r=req_size_dist[idx_t[0:5],2]

str_list=['Size Distribution (cont)','Basic Properties','Top 5 Freq']
y_list=['1','2','3','4','5']
x_list=['Comb size','Comb freq','Write size','Write freq','Read size','Read freq']
V=[idx_t[0:5]+1, va_t, idx_w[0:5]+1, va_w,  idx_r[0:5]+1, va_r]
generate_table_page(prs, asarray(V), str_list,x_list,y_list,options=0,create_page=1)

## table 2
x_list=['Ratio >size','Comb','Write','Read','Ratio <=size','Comb','Write','Read']
size_set=2.0 ** (arange(3,11))
a=len(size_set)
V=zeros((8,a))
for i in arange(a):
    V[1:4,i]=(1 - req_size_cdf[int(size_set[i]-1),:]).T
    V[5:8,i]=(req_size_cdf[int(size_set[i]-1),:]).T

V[0,:]=size_set
V[4,:]=size_set

y_list=[]
for i in arange(a):
    y_list.append(str(i))
generate_table_page(prs, asarray(V), str_list,x_list,y_list,options=0,create_page=1)


### generate LBA-size distribution

filenames=(['lba_size_freq_com.jpg','lba_size_freq_write.jpg','lba_size_freq_read.jpg'])
temp_str1='Observe the additional LBA information for sequence/randomness distribition'
temp_str2='The more large-size requests and the more narrow LBA range, the more sequetial in a sense '
temp_str3='Provide more information than "size vs frequency" curve, but difficult to observe'
content=([temp_str1,temp_str2,temp_str3])
str_list=["LBA-Size Distribution",'Basic Properties' ]
generate_3fig_page(prs,filenames,str_list, content)


### generate Queued next seek distance distribution
filenames=(['sk_mode.png','sk_mean.png','sk_abs_mean.png','sk_max.png'])
str_list=["Queued Next Seek Distance",'Advanced Properties' ]
generate_4fig_page(prs,filenames,str_list, [''])



### generate Queued next seek distance distribution (cont)

out_slide_layout = prs.slide_layouts[4]
# Create the summary graph
out_slide = prs.slides.add_slide(out_slide_layout)
title = out_slide.shapes.title
title.text = "Queued Next Seek Distance (cont)"
subtitle = out_slide.placeholders[11]
subtitle.text = "Advanced Properties"   

options.seek = [0.1,0.2,0.5,0.8]
options.seek_delta = [0.01,0.1,0.2]
temp_str1='Observe the mode value vs ratio; when value is zero, the higher the ratio, the more sequential the workload'
temp_str3='Observe if seek distance drop quickly wrt queue length; if so, the stream is mixed and cache plays important role'
temp_str2='Sequence vs Randomness'

add_items_to_tf(out_slide, temp_str1, [],font_size)
add_items_to_tf(out_slide, temp_str3, [],font_size)
add_items_to_tf(out_slide, temp_str2, seq_rand_str,font_size)


### generate Sequential CMD Ratio

if hasattr(options,'seq_size_threshold'):
    seq_size_threshold=options.seq_size_threshold
else:
    seq_size_threshold=1024

filenames=['seq_cmd_ratio.png','seq_cmd_ratio_size_'+str(seq_size_threshold)+'.png']
temp_str1='Observe sequence ratio with or without size constraint'
temp_str11='If the ratio changes sharply wrt queue length, the workload has strong mixed streams, i.e., the cache shall play important role; otherwise, if the curve is flat, there is no or less (mixed) streams'
temp_str12='If the ratio with size contraint is much smaller than the one without, the average stream size is small (default 1024 blocks); '
content=[temp_str1, [temp_str11,temp_str12]]

str_list=["Sequential CMD Ratio","Advanced Properties" ]
generate_2fig_page(prs,filenames,str_list, content)


### generate Near Sequential CMD Ratio
filenames=['near_seq_cmd_ratio.png','near_seq_cmd_ratio_size_'+str(seq_size_threshold)+'.png']
temp_str1='Observe near sequence ratio with or without size constraint'
temp_str11='If the ratio changes sharply wrt queue length, the workload has strong mixed streams, i.e., the cache shall play important role; otherwise, if the curve is flat, there is no or less (mixed) streams'
temp_str12='If the ratio with size contraint is much smaller than the one without, the average stream size is small (default 1024 blocks); '
temp_str2='Compare the surves with or without gap to check the locality '
content=[temp_str1, [temp_str11,temp_str12], temp_str2,[]]

str_list=["Near Sequential CMD Ratio","Advanced Properties" ]
generate_2fig_page(prs,filenames,str_list, content)


### generate Frequented Write Update

filenames=(['freq_update_c.png','freq_update_b.png'])

#a0=size(freq_wow_record.freq_hit,1)
temp_hit=np.squeeze(freq_wow_record.freq_hit)/(freq_wow_record.freq_idx)
amp_ratio=sum(freq_wow_record.freq_hit)*1.0 / sum(temp_hit)
temp_str1='Observe frequented write update blk & cmd ratio for write amplifcation (WA) & hit frequency for cache'
temp_str11='Higher cmd update ratio than blk ratio usually leads to much higher WA ratio than the mininum ratio; if cmd and blk ratios are close, minimun WA is possible'
temp_str12='High hit frequency usually means the necesity of write cache subject to hit recency'
temp_str2=(('Updated blk ratio '+"{0:.3f}".format(1 - squeeze(freq_wow_record.freq_cdf[0]))+'& Updated cmd ratio: freq '+"{0:.3f}".format(1 - squeeze(freq_wow_record.c_freq_cdf[0]))))
temp_str3=(('The minimun amplification ratio is '+"{0:.3f}".format(amp_ratio)+', if only the updated blocks in one request are written to the new places'))

content=[temp_str1, [temp_str11,temp_str12], temp_str2,[],temp_str3,[]]
str_list=["Frequented Write Update","Advanced Properties" ]
generate_2fig_page(prs,filenames,str_list, content)


### generate Timed Write Update
filenames=(['timed_update1.png','timed_update2.png'])
a1=len(time_wow_record.hit_ratio)
temp_str1='Observe timed write update blk & cmd ratio for write amplifcation (WA) & update trend vs time'
temp_str11='Higher cmd update ratio than blk ratio usually leads to much higher WA ratio than the mininum ratio; if cmd and blk ratios are close, minimun WA is possible'
temp_str12='A linear line usually means a relatively steady update trend, i.e., the update is relatively constant for this workload'
temp_str2=(('Updated blk ratio '+"{0:.3f}".format(squeeze(time_wow_record.update_ratio[a1-1]) / squeeze(time_wow_record.write_ratio[a1-1]))+'& Updated cmd ratio: freq '+"{0:.3f}".format(squeeze(time_wow_record.hit_ratio[a1-1])/squeeze( time_wow_record.write_cmd_ratio[a1-1]))))
temp_str3=(('The minimun amplification ratio is '+"{0:.3f}".format(1.0 / (1 - squeeze(time_wow_record.update_ratio[a1-1]) /squeeze( time_wow_record.write_ratio[a1-1])))+', if only the updated blocks in one request are written to the new places'))

content=[temp_str1, [temp_str11,temp_str12], temp_str2,[],temp_str3,[]]
str_list=["Timed Write Update","Advanced Properties" ]
generate_2fig_page(prs,filenames,str_list, content)


### generate Stack Distance


temp_str1='Observe the peak of frequency/distribution to locate the most possible hit time, and thefore the cache size'
idx_pa=argsort(-stack_wow_record.stack_dist_record_partial[:,0])
idx_fu=argsort(-stack_wow_record.stack_dist_record_full[:,0])
va_pa=stack_wow_record.stack_dist_record_partial[idx_pa[0:5],0]
va_fu=stack_wow_record.stack_dist_record_full[idx_fu[0:5],0]

str1=''
str2=''
str3=''
str4=''
for i in arange(5).reshape(-1):
    if len(va_pa)>0:
        str1=((str1+str(int(va_pa[i]))+','))
        str3=((str3+str(idx_pa[i]+1)+','))
    if len(va_fu)>0:
        str2=((str2+str(int(va_fu[i]))+','))
        str4=((str4+str(idx_fu[i]+1)+','))

temp_str1=''
temp_str2=''
temp_str3=''
temp_str4=''
if (len(va_pa)>0):
    temp_str1=(('The top 5 partial hit frequency are '+str1+' with stack distance '+str3))
    temp_str2=(('The stack distances '+str(idx_pa[1])+' is roughly '+"{0:.3f}".format(1.0*(idx_pa[1]+1) / basic_info.iops_write)+' seconds'))

if len(va_fu)>0:
    temp_str3=(('The top 5 full hit frequency are '+str2+' with stack distance '+str4))
    temp_str4=(('The stack distances '+str(idx_fu[1])+' is roughly '+"{0:.3f}".format(1.0*(idx_fu[1]+1) / basic_info.iops_write)+' seconds'))
#
content=[temp_str2,[],temp_str1,[],temp_str4,[],temp_str3,[]]
#exportToPPTX('addtext',content,'Position','Text_main','Font',14)

pic_name='stack_dist_write.png'
im=Image.open(pic_name,'r')
iw,ih=im.size 
im.close()

height=4
width=(1.0*height/ih*iw)
top=1.3
left=((slide_width-width)/2)
str_list=['Stack Distance (Write)','Advanced Properties' ]

locations=slide_info_class(width=width, height=height,top=top,left=left,font_size=14)
generate_1fig_page(prs,[pic_name],str_list, content, locations)


## generate  Write Hit LBA & Size Dist


filenames=(['WU_LBA_dist.png','WU_size_dist.png'])


lba_dist=stack_wow_record.lba_dist
idx_pa=argsort(-lba_dist[:,1])
idx_fu=argsort(-lba_dist[:,0])
va_pa=lba_dist[idx_pa[0:5],1]
va_fu=lba_dist[idx_fu[0:5],0]

al,bl=shape(lba_dist)

temp_str1='Observe hit frequency vs size/LBA distribution'
str1=''
str2=''
str3=''
str4=''
for i in arange(5).reshape(-1):
    str1=((str1+str(va_pa[i])+','))
    if idx_pa[i] == al-1:
        str2=((str2+'['+str(int(lba_dist[idx_pa[i],2])),','+str(int(lba_dist[idx_pa[i],2] + 1024)),'), '))
    else:
        str2=((str2+'['+str(int(lba_dist[idx_pa[i],2]))+','+str(int(lba_dist[idx_pa[i] + 1,2]))+'), '))
    str3=((str3+str(va_fu[i])+','))
    if idx_fu[i] == al-1:
        str4=str4+'['+str(int(lba_dist[idx_fu[i],2]))+','+str(int(lba_dist[idx_fu[i],2] + 1024))+'), '
    else:
        str4=str4+'['+str(int(lba_dist[idx_fu[i],2]))+','+str(int(lba_dist[idx_fu[i] + 1,2]))+'), '

temp_str2=(('The top 5 partial hit frequency are '+str1+' in the LBA range of '+str2))
temp_str3=(('The top 5 full hit frequency are '+str3+' in the LBA range of  '+str4))
size_dist=stack_wow_record.size_dist

idx_pa=argsort(-size_dist[:,1])
idx_fu=argsort(-size_dist[:,0])
va_pa=size_dist[idx_pa[0:5],1]
va_fu=size_dist[idx_fu[0:5],0]

str1=''
str2=''
str3=''
str4=''
for i in arange(5).reshape(-1):
    str1=((str1+str(va_pa[i])+', '))
    str2=((str2+str((idx_pa[i]))+', '))
    str3=((str3+str(va_fu[i])+', '))
    str4=((str4+str((idx_fu[i]))+', '))

temp_str4=(('The top 5 partial hit frequency are '+str1+' with the block size '+str3))
temp_str5=(('The top 5 full hit frequency are '+str2+' with the block size  '+str4))
content=([temp_str1,[],temp_str2,[],temp_str3,[],temp_str4,[],temp_str5,[]])

str_list=["Write Hit LBA & Size Dist","Advanced Properties" ]
generate_2fig_page(prs,filenames,str_list, content)



## generate  Stacked Write Update
filenames=(['stacked_update1.png','stacked_update2.png'])

# find the stack distance for corresponding persentage
cdf_record_full=stack_wow_record.cdf_record_full
cdf_record_partial=stack_wow_record.cdf_record_partial
a1=len(cdf_record_full)
a2=len(cdf_record_partial)
if a1 == a2:
    a=copy(a1)
    cdf_record_comb=copy(cdf_record_full)
    cdf_record_comb[:,1:3]=cdf_record_full[:,1:3] + cdf_record_partial[:,1:3]
else:
    if (a1 > a2):
        a=copy(a1)
        cdf_record_comb=copy(cdf_record_full)
        if (a2 > 0):
            cdf_record_comb[:a2,1:3]=cdf_record_full[:a2,1:3] + cdf_record_partial[:a2,1:3]
            cdf_record_comb[a2:a1,1:3]=cdf_record_full[a2 :a1,1:3] + squeeze([ones((a1-a2,1))*(cdf_record_partial[a2-1,1]), ones((a1-a2,1))*(cdf_record_partial[a2-1,2])]).T
    else:
        a=copy(a2)
        cdf_record_comb=copy(cdf_record_partial)
        if (a1 > 0):
            cdf_record_comb[:a1,1:3]=cdf_record_full[:a1,1:3] + cdf_record_partial[:a1,1:3]
            cdf_record_comb[a1:a2,1:3]=squeeze([(ones((a2 - a1,1))*cdf_record_full[a1-1,1]), ones((a2 - a1,1))*cdf_record_full[a1-1,1:3]]).T + cdf_record_partial[a1 :a2,1:3]
        # disp('no record found');

hit_set=[0.2,0.4,0.6,0.8,0.9]
a3=len(hit_set)
str1=''
str2=''
str3=''
str4=''
for i in arange(5).reshape(-1):
    str1=((str1+str(hit_set[i])+','))
    if a1 != 0:
        va_fu=dot(cdf_record_full[a1-1,1],hit_set[i])
        idx_fu=nonzero(cdf_record_full[:,1] >= va_fu)[0][0]+1
        str2=((str2+str(idx_fu)+','))
    if a2 != 0:
        va_pa=dot(cdf_record_partial[a2-1,1],hit_set[i])
        idx_pa=nonzero(cdf_record_partial[:,1] >= va_pa)[0][0]+1
        str3=((str3+str(idx_pa)+','))
    if a != 0:
        va_co=dot(cdf_record_comb[a-1,1],hit_set[i])
        idx_co=nonzero(cdf_record_comb[:,1] >= va_co)[0][0]+1
        str4=((str4+str(idx_co)+','))
        str5=((str4+str((idx_co*basic_info.ave_size_write))+','))

temp_str1='Observe reasonable distance range for cache allocation'
temp_str2=(('The CDF rates of '+str1+' are achieved at stack distance of '))
temp_str21=((str2+' for full hit'))
temp_str22=((str3+' for partial hit'))
temp_str23=((str4+'for combined hit'))
temp_str3=(('To achieve the combined CDF rates of '+str1+' at least '+str5+' blocks of write cache are required in ideal situations, respectively'))

content=([temp_str1,[],temp_str2,[temp_str21,temp_str22,temp_str23],temp_str3,[]])
str_list=["Stacked Write Update","Advanced Properties" ]
generate_2fig_page(prs,filenames,str_list, content)

## generate  Idle time
filenames=(['est_dev_cdf_idle_time.png','est_dev_cdf_idle_time_f.png','est_dev_idle_time.png'])
str_list=["Estimated Idle Time ","Advanced Properties" ]

temp_str1='Observe whether the (effective)idle time is enough for background activities'
temp_str2=(('Total effective time='+"{0:.3f}".format(lists_action[aa-1,1] - lists_action[0,1])+'; maximum time='+"{0:.3f}".format(lists_action[aa-1,1])))
idx=nonzero(idle_queue_record.idle_time_array[:,1] > 0.1)
temp_str3=(('Total effective idle time (>0.1s)='+"{0:.3f}".format(sum(idle_queue_record.idle_time_array[idx,1]))+'; Total idle time='+"{0:.3f}".format(sum(idle_queue_record.idle_time_array[:,1]))))
temp_str4=(('Total effective idle frequency (>0.1s)='+str(shape(idx)[1])+'; Total idle frequency ='+str(len(idle_queue_record.idle_time_array))))
content=([temp_str1,temp_str2,temp_str3,temp_str4])
generate_3fig_page(prs,filenames,str_list, content)

#prs.save('analysis_report.pptx')
prs.save(options.ppt_name)